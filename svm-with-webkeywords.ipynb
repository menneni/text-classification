{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stopwords = \"based serive services amp /n /r ltd provide year company special  giving established various became 1987 range like every center best quality shop india indian complete range leading concern like time latest every one well-known also south delhi mumbai india indian bangalore hyderabad chennai\"\n",
    "stoplist += more_stopwords.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'i'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import sparse\n",
    "\n",
    "def loadData(filePath=\"dataset.csv\"):\n",
    "\tdata=pd.read_csv(\"/home/administrator/data/categories-data/Train-Data/fps-with-cat-train.csv\") \n",
    "\tdata['CategoryFB'] = data['CategoryFB'].fillna(data['CategoryV2'])\n",
    "\tdata['Description'] = data['Description'].fillna(data['Name'])\n",
    "\treturn data[\"Tag\"],data[\"Description\"],data[\"CategoryV2\"]\n",
    "\n",
    "def preProcessing(features):\n",
    "    num_descs = features.size\n",
    "    clean_wordlist = []\n",
    "    clean_descs = []\n",
    "    stops = set(stopwords.words('english'))\n",
    "    more_stopwords = \"based nwe n r amp ncar nagar nto nand quot k provide service services year giving established various became 1987 range like every center best quality india indian complete range leading concern like time latest every one well-known also south delhi mumbai india indian bangalore hyderabad chennai\"\n",
    "    stops.update(more_stopwords.split())\n",
    "    for i in range( 0, num_descs):\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", features[i]) \n",
    "        words = letters_only.lower().split()\n",
    "        words = [w.lower() for w in words if not w in stops]  \n",
    "        clean_wordlist.append(words)\n",
    "        clean_descs.append(\" \".join(words))\n",
    "    return clean_descs, clean_wordlist\n",
    "\n",
    "\n",
    "def getDTMByTFIDF(features,nfeatures):\n",
    "    tfIdf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), min_df = 10, stop_words = 'english', max_features=nfeatures)\n",
    "    dtm = tfIdf_vectorizer.fit_transform(features).toarray()\n",
    "    return dtm,tfIdf_vectorizer\n",
    "\n",
    "def featuresByChiSq(features,labels,nFeature=3000):\n",
    "    chi2_model = SelectKBest(chi2,k=nFeature)\n",
    "    dtm = chi2_model.fit_transform(features,labels)\n",
    "    return dtm,chi2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(document_term_matrix,labels,classifier=\"SVM\",nfold=10):\n",
    "    clf = None\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    \n",
    "    if classifier == \"RF\":\n",
    "        clf = RandomForestClassifier(class_weight='auto')\n",
    "    elif classifier == \"NB\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier == \"SVM\":\n",
    "        clf = LinearSVC(class_weight='auto')\n",
    "    \n",
    "    skf = StratifiedKFold(labels, n_folds=nfold)\n",
    "\n",
    "    for train_index, test_index in skf:\n",
    "        X_train, X_test = document_term_matrix[train_index], document_term_matrix[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        p,r,f,s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        fscore.append(f)\n",
    "        \n",
    "    return round(np.mean(precision),3),round(np.mean(recall),3),round(np.mean(fscore),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, descs, labels = loadData()\n",
    "processed_descs, processed_descs_wordlist = preProcessing(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARDWARE & SANITARYWARE'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm,vect = getDTMByTFIDF(processed_descs,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisqDtm, chisqModel = featuresByChiSq(dtm,labels,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = crossValidate(chisqDtm,labels,\"SVM\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718 0.407 <function precision_recall_fscore_support at 0x7f2b751b89b0>\n"
     ]
    }
   ],
   "source": [
    "print precision, recall, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_descs, test_descs = train_test_split(descs, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_descs = train_descs.reset_index(drop=True)\n",
    "test_descs = test_descs.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "processed__train_descs, processed_train_descs_wordlist = preProcessing(train_descs)\n",
    "processed_test_descs, processed_test_descs_wordlist = preProcessing(test_descs)\n",
    "\n",
    "dtm_train,vect_train = getDTMByTFIDF(processed__train_descs,2000)\n",
    "chisqDtmTrain, chisqModelTrain = featuresByChiSq(dtm_train,train_labels,2000)\n",
    "\n",
    "clf = LinearSVC(class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_descs, test_descs = train_test_split(descs, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_descs = train_descs.reset_index(drop=True)\n",
    "test_descs = test_descs.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "processed__train_descs, processed_train_descs_wordlist = preProcessing(train_descs)\n",
    "processed_test_descs, processed_test_descs_wordlist = preProcessing(test_descs)\n",
    "\n",
    "dtm_train,vect_train = getDTMByTFIDF(processed__train_descs,1500)\n",
    "chisqDtmTrain, chisqModelTrain = featuresByChiSq(dtm_train,train_labels,1000)\n",
    "\n",
    "clf = LinearSVC(class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model = clf.fit(chisqDtmTrain, train_labels)\n",
    "dtm_test,vect_test = getDTMByTFIDF(processed_test_descs,1500)\n",
    "chisqDtmTest, chisqModelTest = featuresByChiSq(dtm_test,test_labels,1000)\n",
    "y_pred = model.predict(chisqDtmTest)\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(test_labels, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.112858258426 0.136732329085 0.116651822468 None\n"
     ]
    }
   ],
   "source": [
    "print p,r,f,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cdict = defaultdict(list)\n",
    "for i, val in enumerate(labels):\n",
    "    if val in cdict:\n",
    "        cdict[val].extend(processed_descs_wordlist[i])\n",
    "    else:\n",
    "        value = list()\n",
    "        cdict[val] = processed_descs_wordlist[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel: 3596\nhotels: 348\ncity: 319\nrooms: 297\npalace: 258\nlocated: 251\nrestaurant: 224\nbusiness: 196\nhospitality: 193\nluxury: 175\nguests: 170\nwell: 164\nfacilities: 155\ninn: 142\nstay: 140\nroom: 138\ninternational: 136\nstar: 132\nheart: 131\naccommodation: 131\nresidency: 121\nbudget: 116\ncomfort: 114\nstation: 108\nmahabaleshwar: 104\ncomfortable: 102\ndreamland: 101\nrailway: 100\namenities: 98\nworld: 96\noffers: 96\noffer: 95\nsituated: 93\nexperience: 93\nmodern: 92\nhall: 91\nideal: 90\ngrand: 88\nbanquet: 84\nluxurious: 82\nhome: 82\namong: 80\nplace: 79\nequipped: 79\nbus: 79\nclass: 78\nresort: 77\nenjoy: 77\nguest: 76\nmany: 73\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "fq= defaultdict( int )\n",
    "for w in cdict['HOTEL']:\n",
    "    fq[w] += 1\n",
    "    \n",
    "copy = []\n",
    "for k,v in fq.items():\n",
    "    copy.append((v, k))\n",
    "\n",
    "\n",
    "copy = sorted(copy, reverse=True)\n",
    "\n",
    "index = 0\n",
    "for k in copy:\n",
    "    if index == 50:\n",
    "        break\n",
    "    else:\n",
    "        print '%s: %d' %(k[1], k[0])\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n\n           ARCHITECTURE       0.00      0.00      0.00         3\n                   ARTS       0.00      0.00      0.00         2\n             AUTOMOTIVE       0.00      0.00      0.00        17\n           BEAUTY & SPA       0.00      0.00      0.00       171\n                  BLOGS       0.00      0.00      0.00        13\n               CATERING       0.00      0.00      0.00         1\n              CHEMICALS       0.00      0.00      0.00         7\n           CONSTRUCTION       0.00      0.00      0.00         2\n              EDUCATION       0.15      0.09      0.11       400\n            ELECTRONICS       0.22      0.42      0.29       396\n          ENTERTAINMENT       0.00      0.00      0.00         7\n                  EVENT       0.00      0.00      0.00         9\n                FASHION       0.02      0.01      0.01       320\n                FLORIST       0.00      0.00      0.00         4\n       FOOD & BEVERAGES       0.00      0.00      0.00       134\n              FURNITURE       0.17      0.06      0.09       163\n                  GIFTS       0.00      0.00      0.00         3\n                GROCERY       0.00      0.00      0.00         4\nHARDWARE & SANITARYWARE       0.08      0.05      0.06       119\n                 HEALTH       0.00      0.00      0.00         9\n        HOME APPLIANCES       0.00      0.00      0.00         4\n              HOME CARE       0.00      0.00      0.00         3\n       HOME MAINTENANCE       0.00      0.00      0.00        71\n                  HOTEL       0.02      0.01      0.01       306\n                HOUSING       0.00      0.00      0.00         1\n             INDIVIDUAL       0.00      0.00      0.00         7\n         INSURANCE/LOAN       0.00      0.00      0.00         1\n         INSURANE/LOANS       0.00      0.00      0.00         1\n        INTERIOR DESIGN       0.00      0.00      0.00         6\n              JEWELLERY       0.07      0.06      0.06        95\n                   KIDS       0.06      0.07      0.06        15\n                KITCHEN       0.00      0.00      0.00         5\n          MANUFACTURING       0.00      0.00      0.00        23\n                MARBLES       0.00      0.00      0.00         0\n                MEDICAL       0.24      0.28      0.26       442\n                    NGO       0.00      0.00      0.00         1\n                 OTHERS       0.00      0.00      0.00         0\n                   PETS       0.00      0.00      0.00         0\n            PHOTOGRAPHY       0.00      0.00      0.00        61\n              PROMOTION       0.05      0.08      0.06        13\n            REAL ESTATE       0.09      0.08      0.09        75\n                 RETAIL       0.00      0.00      0.00         9\n               SECURITY       0.03      0.03      0.03        74\n                 SPORTS       0.00      0.00      0.00        76\n    TECHNOLOGY SERVICES       0.00      0.00      0.00         2\n                TOURISM       0.18      0.29      0.22       375\n                TRADING       0.00      0.00      0.00         2\n\n            avg / total       0.11      0.14      0.12      3452\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}