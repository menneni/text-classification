{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stopwords = \"based serive services amp /n /r ltd provide year company special  giving established various became 1987 range like every center best quality shop india indian complete range leading concern like time latest every one well-known also south delhi mumbai india indian bangalore hyderabad chennai\"\n",
    "stoplist += more_stopwords.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'i'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec\n",
    "from scipy import sparse\n",
    "\n",
    "def loadData(filePath=\"dataset.csv\"):\n",
    "\tdata=pd.read_csv(\"/home/administrator/data/categories-data/Train-Data/fps-with-cat-train.csv\") \n",
    "\tdata['CategoryFB'] = data['CategoryFB'].fillna(data['CategoryV2'])\n",
    "\tdata['Description'] = data['Description'].fillna(data['Name'])\n",
    "\treturn data[\"Tag\"],data[\"Description\"],data[\"CategoryV2\"]\n",
    "\n",
    "def preProcessing(features):\n",
    "    num_descs = features.size\n",
    "    clean_wordlist = []\n",
    "    clean_descs = []\n",
    "    stops = set(stopwords.words('english'))\n",
    "    more_stopwords = \"based nwe n r amp ncar nagar nto nand quot k provide service services year giving established various became 1987 range like every center best quality india indian complete range leading concern like time latest every one well-known also south delhi mumbai india indian bangalore hyderabad chennai\"\n",
    "    stops.update(more_stopwords.split())\n",
    "    for i in range( 0, num_descs):\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", features[i]) \n",
    "        words = letters_only.lower().split()\n",
    "        words = [w.lower() for w in words if not w in stops]  \n",
    "        clean_wordlist.append(words)\n",
    "        clean_descs.append(\" \".join(words))\n",
    "    return clean_descs, clean_wordlist\n",
    "\n",
    "\n",
    "def getDTMByTFIDF(features,nfeatures):\n",
    "    tfIdf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), min_df = 0, stop_words = 'english', max_features=nfeatures)\n",
    "    dtm = tfIdf_vectorizer.fit_transform(features).toarray()\n",
    "    return dtm,tfIdf_vectorizer\n",
    "\n",
    "def featuresByChiSq(features,labels,nFeature=3000):\n",
    "    chi2_model = SelectKBest(chi2,k=nFeature)\n",
    "    dtm = chi2_model.fit_transform(features,labels)\n",
    "    return dtm,chi2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(document_term_matrix,labels,classifier=\"SVM\",nfold=10):\n",
    "    clf = None\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    \n",
    "    if classifier == \"RF\":\n",
    "        clf = RandomForestClassifier(class_weight='auto')\n",
    "    elif classifier == \"NB\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier == \"SVM\":\n",
    "        clf = LinearSVC(class_weight='auto')\n",
    "    \n",
    "    skf = StratifiedKFold(labels, n_folds=nfold)\n",
    "\n",
    "    for train_index, test_index in skf:\n",
    "        X_train, X_test = document_term_matrix[train_index], document_term_matrix[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model = clf.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        p,r,f,s = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        fscore.append(f)\n",
    "        \n",
    "    return round(np.mean(precision),3),round(np.mean(recall),3),round(np.mean(fscore),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags, descs, labels = loadData()\n",
    "processed_descs, processed_descs_wordlist = preProcessing(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARDWARE & SANITARYWARE'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm,vect = getDTMByTFIDF(processed_descs,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisqDtm, chisqModel = featuresByChiSq(dtm,labels,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = crossValidate(chisqDtm,labels,\"SVM\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93 0.839 <function precision_recall_fscore_support at 0x7f2b751b89b0>\n"
     ]
    }
   ],
   "source": [
    "print precision, recall, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_descs, test_descs = train_test_split(descs, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_descs = train_descs.reset_index(drop=True)\n",
    "test_descs = test_descs.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "processed__train_descs, processed_train_descs_wordlist = preProcessing(train_descs)\n",
    "processed_test_descs, processed_test_descs_wordlist = preProcessing(test_descs)\n",
    "\n",
    "dtm_train,vect_train = getDTMByTFIDF(processed__train_descs,2000)\n",
    "chisqDtmTrain, chisqModelTrain = featuresByChiSq(dtm_train,train_labels,2000)\n",
    "\n",
    "clf = LinearSVC(class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'probability'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-1e87398677c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mchisqDtmTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchisqModelTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturesByChiSq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_descs, test_descs = train_test_split(descs, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels, test_size=0.1, \n",
    "                                           random_state=42)\n",
    "\n",
    "train_descs = train_descs.reset_index(drop=True)\n",
    "test_descs = test_descs.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "test_labels = test_labels.reset_index(drop=True)\n",
    "\n",
    "processed__train_descs, processed_train_descs_wordlist = preProcessing(train_descs)\n",
    "processed_test_descs, processed_test_descs_wordlist = preProcessing(test_descs)\n",
    "\n",
    "dtm_train,vect_train = getDTMByTFIDF(processed__train_descs,1500)\n",
    "chisqDtmTrain, chisqModelTrain = featuresByChiSq(dtm_train,train_labels,1000)\n",
    "\n",
    "clf = LinearSVC(class_weight='auto', probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/class_weight.py:65: DeprecationWarning: The class_weight='auto' heuristic is deprecated in 0.17 in favor of a new heuristic class_weight='balanced'. 'auto' will be removed in 0.19\n  \" 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "model = clf.fit(chisqDtmTrain, train_labels)\n",
    "dtm_test,vect_test = getDTMByTFIDF(processed_test_descs,1500)\n",
    "chisqDtmTest, chisqModelTest = featuresByChiSq(dtm_test,test_labels,1000)\n",
    "y_pred = model.predict(chisqDtmTest)\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(test_labels, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.369468926137 0.290845886443 0.315524252641 None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: EDUCATION",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-f9d101ac2a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/administrator/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/administrator/.local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/administrator/.local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/administrator/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: EDUCATION"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print p,r,f,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cdict = defaultdict(list)\n",
    "for i, val in enumerate(labels):\n",
    "    if val in cdict:\n",
    "        cdict[val].extend(processed_descs_wordlist[i])\n",
    "    else:\n",
    "        value = list()\n",
    "        cdict[val] = processed_descs_wordlist[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel: 3596\nhotels: 348\ncity: 319\nrooms: 297\npalace: 258\nlocated: 251\nrestaurant: 224\nbusiness: 196\nhospitality: 193\nluxury: 175\nguests: 170\nwell: 164\nfacilities: 155\ninn: 142\nstay: 140\nroom: 138\ninternational: 136\nstar: 132\nheart: 131\naccommodation: 131\nresidency: 121\nbudget: 116\ncomfort: 114\nstation: 108\nmahabaleshwar: 104\ncomfortable: 102\ndreamland: 101\nrailway: 100\namenities: 98\nworld: 96\noffers: 96\noffer: 95\nsituated: 93\nexperience: 93\nmodern: 92\nhall: 91\nideal: 90\ngrand: 88\nbanquet: 84\nluxurious: 82\nhome: 82\namong: 80\nplace: 79\nequipped: 79\nbus: 79\nclass: 78\nresort: 77\nenjoy: 77\nguest: 76\nmany: 73\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "fq= defaultdict( int )\n",
    "for w in cdict['HOTEL']:\n",
    "    fq[w] += 1\n",
    "    \n",
    "copy = []\n",
    "for k,v in fq.items():\n",
    "    copy.append((v, k))\n",
    "\n",
    "\n",
    "copy = sorted(copy, reverse=True)\n",
    "\n",
    "index = 0\n",
    "for k in copy:\n",
    "    if index == 50:\n",
    "        break\n",
    "    else:\n",
    "        print '%s: %d' %(k[1], k[0])\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n\n           ARCHITECTURE       0.00      0.00      0.00         3\n                   ARTS       0.00      0.00      0.00         2\n             AUTOMOTIVE       0.00      0.00      0.00        17\n           BEAUTY & SPA       0.00      0.00      0.00       171\n                  BLOGS       0.00      0.00      0.00        13\n               CATERING       0.00      0.00      0.00         1\n              CHEMICALS       0.00      0.00      0.00         7\n           CONSTRUCTION       0.00      0.00      0.00         2\n              EDUCATION       0.15      0.09      0.11       400\n            ELECTRONICS       0.22      0.42      0.29       396\n          ENTERTAINMENT       0.00      0.00      0.00         7\n                  EVENT       0.00      0.00      0.00         9\n                FASHION       0.02      0.01      0.01       320\n                FLORIST       0.00      0.00      0.00         4\n       FOOD & BEVERAGES       0.00      0.00      0.00       134\n              FURNITURE       0.17      0.06      0.09       163\n                  GIFTS       0.00      0.00      0.00         3\n                GROCERY       0.00      0.00      0.00         4\nHARDWARE & SANITARYWARE       0.08      0.05      0.06       119\n                 HEALTH       0.00      0.00      0.00         9\n        HOME APPLIANCES       0.00      0.00      0.00         4\n              HOME CARE       0.00      0.00      0.00         3\n       HOME MAINTENANCE       0.00      0.00      0.00        71\n                  HOTEL       0.02      0.01      0.01       306\n                HOUSING       0.00      0.00      0.00         1\n             INDIVIDUAL       0.00      0.00      0.00         7\n         INSURANCE/LOAN       0.00      0.00      0.00         1\n         INSURANE/LOANS       0.00      0.00      0.00         1\n        INTERIOR DESIGN       0.00      0.00      0.00         6\n              JEWELLERY       0.07      0.06      0.06        95\n                   KIDS       0.06      0.07      0.06        15\n                KITCHEN       0.00      0.00      0.00         5\n          MANUFACTURING       0.00      0.00      0.00        23\n                MARBLES       0.00      0.00      0.00         0\n                MEDICAL       0.24      0.28      0.26       442\n                    NGO       0.00      0.00      0.00         1\n                 OTHERS       0.00      0.00      0.00         0\n                   PETS       0.00      0.00      0.00         0\n            PHOTOGRAPHY       0.00      0.00      0.00        61\n              PROMOTION       0.05      0.08      0.06        13\n            REAL ESTATE       0.09      0.08      0.09        75\n                 RETAIL       0.00      0.00      0.00         9\n               SECURITY       0.03      0.03      0.03        74\n                 SPORTS       0.00      0.00      0.00        76\n    TECHNOLOGY SERVICES       0.00      0.00      0.00         2\n                TOURISM       0.18      0.29      0.22       375\n                TRADING       0.00      0.00      0.00         2\n\n            avg / total       0.11      0.14      0.12      3452\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}